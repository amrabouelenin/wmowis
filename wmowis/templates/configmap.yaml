apiVersion: v1
kind: ConfigMap
metadata:
  name: trino-config
data:
  kafka.properties: |
    connector.name=kafka
    kafka.nodes=wis-kafka.default.svc.cluster.local:9092
  init.sql: |
    -- will be applied in post-install
    CREATE SCHEMA IF NOT EXISTS hive.datalake
    WITH (location = 's3a://wis2obsprocessing/');
    -- will be applied in post-install
    CREATE TABLE IF NOT EXISTS hive.datalake.observations 
    ( 
        "wigos_id" varchar,
        "result_time" timestamp,
        "phenomenon_time" varchar,
        "latitude" double,
        "longitude" double,
        "altitude" double,
        "observed_property" varchar,
        "observed_value" double,
        "observed_unit" varchar,
        "notification_data_id" varchar,
        "notification_pubtime" timestamp,
        "notification_wigos_id" varchar,
        "meta_broker"   varchar,
        "meta_topic"    varchar,
        "meta_time_received" timestamp
    )
    WITH (
        format = 'ORC'
    );
  init.sh: |
    #!/bin/bash
    # blocks until trino is reachable
    echo "starting script to run trino init"
    while ! trino --server wis-trino:8080 --execute 'SHOW CATALOGS' | grep "system"; do
        echo "trino is not reachable, sleeping"
        sleep 5
    done

    # # wait until there is data in the topic
    # while trino --server wis-trino:8080 --execute 'select count(*) from kafka.default."notifications-tostorage"' | grep -e '"0"'; do
    #     echo "No data in the topic, sleeping"
    #     sleep 5
    # done 

    echo -e 'Creating trino catalog'
    cat /scripts/init.sql | trino --server wis-trino:8080

    echo -e 'Successfully created the following catalogs:'
    trino --server wis-trino:8080 --execute 'SHOW CATALOGS'

  etl.sql: |-
    INSERT INTO postgresql.public."kafka_table_offsets"
    SELECT
    "_partition_id", 
    max("_partition_offset"), 
    CURRENT_TIMESTAMP,
    'upper_bound'
    FROM kafka.default."notifications-tostorage" 
    GROUP BY 
    "_partition_id", 
    CURRENT_TIMESTAMP
    ; 

    -- Fetch 
    INSERT INTO  
    hive.datalake.observations 
    SELECT 
    "wigos_id",
    "result_time",
    "phenomenon_time",
    "latitude",
    "longitude",
    "altitude",
    "observed_property",
    "observed_value",
    "observed_unit",
    "notification_data_id",
    "notification_pubtime",
    "notification_wigos_id",
    "meta_broker",
    "meta_topic",
    "meta_time_received"
    FROM
    kafka.default."notifications-tostorage" as ktable 
    JOIN 
    postgresql.public."kafka_table_offsets" as offset_table_lower
    ON ( 
        ktable."_partition_id" = offset_table_lower.kafka_partition_id
    AND 
        ktable."_partition_offset" > offset_table_lower.kafka_partition_offset
    AND
        offset_table_lower.bound = 'lower_bound'
    )
    JOIN
    postgresql.public."kafka_table_offsets" as offset_table_upper  
    ON (
        ktable."_partition_id" = offset_table_upper.kafka_partition_id
    AND 
        ktable."_partition_offset" <= offset_table_upper.kafka_partition_offset
    AND
        offset_table_upper.bound = 'upper_bound'
    );

    DELETE FROM postgresql.public."kafka_table_offsets" WHERE bound = 'lower_bound';

    UPDATE postgresql.public."kafka_table_offsets" SET bound = 'lower_bound' WHERE bound = 'upper_bound';   
  
  etl.sh: |-
    #!/bin/bash
    if trino --server wis-trino:8080 --execute 'select count(*) from postgresql.public."kafka_table_offsets"' |  grep -ve '"0"' ; then
        echo "executing ETL job"
        cat /etl.sql | trino --server wis-trino:8080
    else
        echo "trino schema not yet initialized"
    fi


  notifications-tostorage.json: |
    {
        "tableName": "notifications-tostorage",
        "schemaName": "default",
        "topicName": "notifications-tostorage",
        "message": {
            "dataFormat": "json",
            "fields": [
                {
                    "name": "wigos_id",
                    "mapping": "wigos_id",
                    "type": "VARCHAR"
                },
                {
                    "name": "result_time",
                    "mapping": "result_time",
                    "type": "TIMESTAMP",
                    "dataFormat": "iso8601"
                },
                {
                    "name": "phenomenon_time",
                    "mapping": "phenomenon_time",
                    "type": "VARCHAR"
                },
                {
                    "name": "latitude",
                    "mapping": "latitude",
                    "type": "DOUBLE"
                },
                {
                    "name": "longitude",
                    "mapping": "longitude",
                    "type": "DOUBLE"
                },
                {
                    "name": "altitude",
                    "mapping": "altitude",
                    "type": "DOUBLE"
                },
                {
                    "name": "observed_property",
                    "mapping": "observed_property",
                    "type": "VARCHAR"
                },
                {
                    "name": "observed_value",
                    "mapping": "observed_value",
                    "type": "DOUBLE"
                },
                {
                    "name": "observed_unit",
                    "mapping": "observed_unit",
                    "type": "VARCHAR"
                },
                {
                    "name": "notification_data_id",
                    "mapping": "notification_data_id",
                    "type": "VARCHAR"
                },
                {
                    "name": "notification_pubtime",
                    "mapping": "notification_pubtime",
                    "type": "TIMESTAMP",
                    "dataFormat": "iso8601"
                },
                {
                    "name": "notification_wigos_id",
                    "mapping": "notification_wigos_id",
                    "type": "VARCHAR"
                },
                {
                    "name": "meta_broker",
                    "mapping": "meta_broker",
                    "type": "VARCHAR"
                },
                {
                    "name": "meta_topic",
                    "mapping": "meta_topic",
                    "type": "VARCHAR"
                },
                {
                    "name": "meta_time_received",
                    "mapping": "meta_time_received",
                    "type": "TIMESTAMP",
                    "dataFormat": "iso8601"
                }
            ]
        }
    }
{{- range $key, $value := .Values.trino.additionalCatalogs }}
  {{ $key }}.properties: |-
{{ $value | indent 4 }}
{{- end }}